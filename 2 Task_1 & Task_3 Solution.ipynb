{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c696abff-50d2-4102-a1f7-9e2f7bf93c05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "library(readr)\n",
    "library(fs)\n",
    "library(sparklyr)\n",
    "library(dplyr)\n",
    "library(glue)\n",
    "library(tidyr)\n",
    "library(DBI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b6aa26b-2e70-41b0-b9ae-91e50bbd95d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 1. Load data\n",
    "\n",
    "Use Auto Loader to Load all .csv into delta table. We put this table as our bronze layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d268689-f20a-4c30-83dd-cfb80b4590ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create checkpoint location in Volume\n",
    "dbutils.fs.mkdirs(\"/Volumes/dev/bronze/raw_data/checkpoint/autoloader\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8611f2a-8e3c-426b-97be-a2cece545451",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    " %python\n",
    "\n",
    " # Read files using Auto Loader with checkpoint\n",
    " # and schema location \"/Volumes/dev/bronze/raw_data/checkpoint/autoloader\"\n",
    " #.option(\"cloudFiles.schemaHints\", \"Quantity int, UnitPrice double\")\n",
    "\n",
    "df = (\n",
    "    spark.readStream.format(\"cloudFiles\")\n",
    "    .option(\"cloudFiles.format\", \"csv\")\n",
    "    .option(\"pathGlobFilter\", \"*.csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"cloudFiles.schemaHints\", \"EvapA_Var1 int, EvapB_Var1 int, EvapC_Var1 int,EvapA_Var2 float, EvapB_Var2 float, EvapC_Var2 float, EvapA_State TinyInt, EvapB_State TinyInt, EvapC_State TinyInt\")\n",
    "    .option(\"cloudFiles.schemaLocation\", \"/Volumes/dev/bronze/raw_data/checkpoint/autoloader\")\n",
    "    .load(\"/Volumes/dev/bronze/raw_data/files/*\")\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b4e7e05-7890-4408-b1e1-15b3ceb134f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "\n",
    "# Write data to delta table - dev.bronze.evap_raw_al\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "(\n",
    "    df\n",
    "    .withColumn(\"__file\",col(\"_metadata.file_name\"))\n",
    "    .writeStream\n",
    "    .option(\"checkpointLocation\", \"/Volumes/dev/bronze/raw_data/checkpoint/autoloader\")\n",
    "    .outputMode(\"append\")\n",
    "    .trigger(availableNow=True)\n",
    "    .toTable(\"dev.bronze.evap_raw_al\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc66c25f-7d0e-4033-8ed0-cab1cdaf67c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql \n",
    "select * from dev.bronze.evap_raw_al "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7a91c8b-2d0e-42a5-8e46-fe4b9a26b9a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select `__file`,count(1) from dev.bronze.evap_raw_al group by `__file`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05378f1a-e075-410b-a1e6-18cd288635c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 2. Wide Format Data\n",
    "\n",
    "Perform wide format processing on the data based on the input date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8877092-9627-4ba8-9d8b-2f687f1cb47e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create View to Wide Format Data\n",
    "\n",
    "# 1. Specifies the date, if no date is specified, defaut day is yesterday\n",
    "\n",
    "dbutils.widgets.text(\"Date\",format(Sys.Date()-1, \"%Y-%m-%d\"), \"Date of Analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd1194aa-235c-4e6c-9216-271e5eb00413",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# get input_date\n",
    "\n",
    "input_date <- dbutils.widgets.get(\"Date\")\n",
    "\n",
    "print(input_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e83e259-9d74-4e0e-8f1d-4dba7254c210",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sc <- spark_connect(method = \"databricks\")  \n",
    "\n",
    "query <- paste0(\"SELECT * FROM dev.bronze.evap_raw_al WHERE `__file` LIKE '\", input_date, \"%'\")\n",
    "df_raw <- dbGetQuery(sc,query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eec01a5c-cf33-4c60-8d52-c0a7ab973e48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "head(df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e7bc7e2-2000-4cf8-8bb8-4a3cf412fb46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Step2.1 Task_3 (interspersed with a process)\n",
    "Entering data from the previous day and converting it.\n",
    "\n",
    "The idea is to calculate the length of the data from the previous day when the Evap A or B or C data was converted at the last moment, and the shortest data will be considered as the data to be converted. The shortest data will be considered as the data to be converted and saved in Silver's temporary table for Task_2 to take into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebd6a5cf-88f9-4953-8199-9c77c2d83fcb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "before_input_date=as.Date(input_date)-1\n",
    "print(input_date)\n",
    "print(before_input_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e8a287f-67b2-4de1-b9bc-ce65463d318e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query <- paste0(\"SELECT * FROM dev.bronze.evap_raw_al WHERE `__file` LIKE '\", before_input_date, \"%'\")\n",
    "df_raw_before <- dbGetQuery(sc,query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eaaef887-269d-4e2a-8b56-5b50f5f1952d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "head(df_raw_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9930c98-64e5-41cf-9c4d-0bddac288347",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Task 3\n",
    "# Get the data length for each EvapA_State or EvapB_State or EvapC_State has change\n",
    "\n",
    "# 1. Calculating the EvapA_State EvapB_State EvapC_State column difference\n",
    "state_diff_A <- diff(df_raw_before$EvapA_State)\n",
    "state_diff_B <- diff(df_raw_before$EvapB_State)\n",
    "state_diff_C <- diff(df_raw_before$EvapC_State)\n",
    "\n",
    "# 2. Find the location of the last state change\n",
    "last_change_index_A <- max(which(state_diff_A != 0))\n",
    "last_change_index_B <- max(which(state_diff_B != 0))\n",
    "last_change_index_C <- max(which(state_diff_C != 0))\n",
    "\n",
    "# 3. Compare these data, find the Max of them\n",
    "\n",
    "last_change_index <- max(last_change_index_A,last_change_index_B,last_change_index_C)\n",
    "\n",
    "# 4. Calculate the number of rows remaining from the last change to the end of the data\n",
    "remaining_rows <- nrow(df_raw_before) - last_change_index\n",
    "\n",
    "# output result\n",
    "remaining_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5c16cfd-3839-40a9-bb38-ff1031f2c598",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Test: delete the last row for testing\n",
    "# df_raw_before <- df_raw_before[-nrow(df_raw_before), ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e391efb1-a117-4a28-b44f-9495923f6951",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get the remaining_rows row\n",
    "df_remaining_rows <- tail(df_raw_before, remaining_rows)\n",
    "print(df_remaining_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f9d0d00-c82e-43a8-9211-25fff17308c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Combine the data\n",
    "df_raw <- bind_rows(df_remaining_rows,df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38c281f3-3001-4cc3-a61e-f50692ca801a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ea0e5da-91ef-4b4e-a472-6349c37d80c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Continuing Wide Format Data Operations\n",
    "# Extend Wide Format so that State=1 and State=0 data are stored separately.\n",
    "df_wide <- df_raw %>%\n",
    "  mutate(\n",
    "    # EvapA state splitting\n",
    "    EvapA_Var1_State1 = ifelse(EvapA_State == 1, EvapA_Var1, NA),\n",
    "    EvapA_Var1_State0 = ifelse(EvapA_State == 0, EvapA_Var1, NA),\n",
    "    EvapA_Var2_State1 = ifelse(EvapA_State == 1, EvapA_Var2, NA),\n",
    "    EvapA_Var2_State0 = ifelse(EvapA_State == 0, EvapA_Var2, NA),\n",
    "\n",
    "    # EvapB state splitting\n",
    "    EvapB_Var1_State1 = ifelse(EvapB_State == 1, EvapB_Var1, NA),\n",
    "    EvapB_Var1_State0 = ifelse(EvapB_State == 0, EvapB_Var1, NA),\n",
    "    EvapB_Var2_State1 = ifelse(EvapB_State == 1, EvapB_Var2, NA),\n",
    "    EvapB_Var2_State0 = ifelse(EvapB_State == 0, EvapB_Var2, NA),\n",
    "\n",
    "    # EvapC state splitting\n",
    "    EvapC_Var1_State1 = ifelse(EvapC_State == 1, EvapC_Var1, NA),\n",
    "    EvapC_Var1_State0 = ifelse(EvapC_State == 0, EvapC_Var1, NA),\n",
    "    EvapC_Var2_State1 = ifelse(EvapC_State == 1, EvapC_Var2, NA),\n",
    "    EvapC_Var2_State0 = ifelse(EvapC_State == 0, EvapC_Var2, NA)\n",
    "  ) %>%\n",
    "  select(Date_time, \n",
    "         EvapA_Var1_State1, EvapA_Var1_State0, EvapA_Var2_State1, EvapA_Var2_State0,\n",
    "         EvapB_Var1_State1, EvapB_Var1_State0, EvapB_Var2_State1, EvapB_Var2_State0,\n",
    "         EvapC_Var1_State1, EvapC_Var1_State0, EvapC_Var2_State1, EvapC_Var2_State0\n",
    "         )\n",
    "\n",
    "# Prints processed Wide format data\n",
    "head(df_wide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57ebd877-40f5-4361-9fae-ace6c038fc1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step 3. Stored in Spark Temporary Table\n",
    "\n",
    "Preparation for Task 2 can also be done into a Spark persistent table, in this case a temporary table is used because the calculations are done on a daily basis. If you rewrite the data, the previous data will disappear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53c7381c-a989-4ba8-8251-d5868245e87b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "-- create silver layer\n",
    "\n",
    "CREATE SCHEMA IF NOT EXISTS dev.silver;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e439997-73ad-4aeb-aa69-871f6e8768b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_wide_spark <- copy_to(sc, df_wide, \"df_wide_temp\", overwrite = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45791ba6-61bb-477c-b6ee-02540f5e0854",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "head(df_wide_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f087d35-b3df-482a-89c3-a3379c2b2913",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark_write_table(df_wide_spark, \"dev.silver.evap_daily_temp\", mode = \"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ea17e94-247a-4cbc-8ae6-525ff3de0765",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "select * from dev.silver.evap_daily_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "930e633e-f43c-4ddb-986f-7fc659771bb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "row_count <- df_wide_spark %>% sdf_nrow()\n",
    "dbutils.notebook.exit(as.character(row_count))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "2"
   },
   "language": "r",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2 Task_1 & Task_3 Solution",
   "widgets": {
    "Date": {
     "currentValue": "2025-02-02",
     "nuid": "fa5091f4-c33c-4538-99bc-f0a7a4c48a59",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "2025-02-01",
      "label": "Date of Analysis",
      "name": "Date",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "2025-02-01",
      "label": "Date of Analysis",
      "name": "Date",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "r"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
